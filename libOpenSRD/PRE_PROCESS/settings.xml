<?xml version="1.0"?>
<opencv_storage>
<Settings>

  <!-- Amount of threads used-->
  <ThreadAmount>1</ThreadAmount>

  <!-- Show image with found corners or not-->
  <showCorners>0</showCorners>
  <!-- Save errors in text file-->
  <saveErrors>1</saveErrors>
  <!-- Save feature coordinates in text file-->
  <saveFeatureCoordinates>1</saveFeatureCoordinates>
  <!-- Save camera pose estimation in text file-->
  <saveCameraPose>1</saveCameraPose>

  <!-- Type of reference input: image->true:1, file->false:0-->
  <InputTypeRef>1</InputTypeRef>
  <!-- Type of input: images->true:1, file->false:0-->
  <InputType>1</InputType>
  <!-- Location of checherboard vertices w.r.t. to world coordinate system during camera pose estimation for camera 1-->
  <InputInitial1>"PRE_PROCESS/VerticesPoseEstimation1.txt"</InputInitial1>
  <!-- Location of checherboard vertices w.r.t. to world coordinate system during camera pose estimation for camera 2-->
  <InputInitial2>"PRE_PROCESS/VerticesPoseEstimation2.txt"</InputInitial2>
  <!-- Location of checherboard vertices w.r.t. to world coordinate system during camera pose estimation for camera 3-->
  <InputInitial3>"PRE_PROCESS/VerticesPoseEstimation3.txt"</InputInitial3>
  <!-- Fixed location of points f for camera 1-->
  <InputFeatures1>"PRE_PROCESS/FeaturesF1.txt"</InputFeatures1>
  <!-- Fixed location of points f for camera 2-->
  <InputFeatures2>"PRE_PROCESS/FeaturesF2.txt"</InputFeatures2>
  <!-- Fixed location of points f for camera 3-->
  <InputFeatures3>"PRE_PROCESS/FeaturesF2.txt"</InputFeatures3>
  <!-- The name of the input directory of camera 1-->
  <InputDirectory1>"DATA/CAM1"</InputDirectory1>
  <!-- The name of the input directory of camera 2-->
  <InputDirectory2>"DATA/CAM2"</InputDirectory2>
  <!-- The name of the input directory of camera 3-->
  <InputDirectory3>"DATA/CAM3"</InputDirectory3>
  <!-- The name of the reference image/file - camera 1-->
  <InputReference1>"PRE_PROCESS/REF1.png"</InputReference1>
  <!-- The name of the reference image - camera 2-->
  <InputReference2>"PRE_PROCESS/REF2.png"</InputReference2>
  <!-- The name of the reference image - camera 3-->
  <InputReference3>"PRE_PROCESS/REF3.png"</InputReference3>
  
  <!-- The name of the calibration file of the camera 1-->
  <CalibrationFile1>"PRE_PROCESS/Calib_C1.yml"</CalibrationFile1>
  <!-- The name of the calibration file of the camera 2-->
  <CalibrationFile2>"PRE_PROCESS/Calib_C2.yml"</CalibrationFile2>
  <!-- The name of the calibration file of the camera 3-->
  <CalibrationFile3>"PRE_PROCESS/Calib_C3.yml"</CalibrationFile3>
  
  <!-- The name of ouput file for optimized coefficients according to chosen surface model-->
  <OutputFileName>"/RESULTS/coeffs.txt"</OutputFileName>
  <!-- The name of ouput file for average error per frame-->
  <OutputFileNameErrors>"/RESULTS/errors.txt"</OutputFileNameErrors>
  
  <!-- The name of ouput file for saving camera pose estimation camera 1-->
  <OutputCameraPose1>"/RESULTS/camerapose1.txt"</OutputCameraPose1>
  <!-- The name of ouput file for saving camera pose estimation camera 2-->
  <OutputCameraPose2>"/RESULTS/camerapose2.txt"</OutputCameraPose2>
  <!-- The name of ouput file for saving camera pose estimation camera 3-->
  <OutputCameraPose3>"/RESULTS/camerapose3.txt"</OutputCameraPose3>
  
  <!-- The name of ouput directory for saving feature coordinates camera 1-->
  <OutputDirectory1>"/RESULTS/FEATURES1"</OutputDirectory1>
  <!-- The name of ouput directory for saving feature coordinates camera 2-->
  <OutputDirectory2>"/RESULTS/FEATURES2"</OutputDirectory2>
  <!-- The name of ouput directory for saving feature coordinates camera 3-->
  <OutputDirectory3>"/RESULTS/FEATURES3"</OutputDirectory3>
    
  <!-- Amount of parameters used-->
  <SurfaceModel>5</SurfaceModel>
  <!-- Length scale in x-direction (crosswise direction)(mm)-->
  <Lx>40</Lx>
  <!-- Length scale in y-direction (streamwise direction)(mm)-->
  <Ly>160</Ly>
  <!-- Initial guess to start optimization in each thread-->
  <Initialguess>"[70.0,0.000,0.000,0.000,0.000]"</Initialguess>
  <!-- Scaling of coefficients for optimization (length=SurfaceModel)-->
  <Scaling>"[1.0,10.000,10.000,10.000,10.000]"</Scaling>

  <!-- Number of inner corners per a item row and column. (square)  -->
  <BoardSize_Width>9</BoardSize_Width>
  <BoardSize_Height>14</BoardSize_Height>
  <PatternSize_Width>10</PatternSize_Width>
  <PatternSize_Height>20</PatternSize_Height>
  <!-- The threshold parameter for response strength corners-->
  <ResponseThreshold>350</ResponseThreshold>
  <!-- The minimum distance in pixels between corner points-->
  <MinDistance>15</MinDistance>
  <!-- The radius to calculate corner response: 5 or 10 currently possible -->
  <responseRadius>5</responseRadius>
  <!-- The max distance between located and predicted feature point -->
  <MatchesThreshold>10</MatchesThreshold>
  
  <!-- Amount of camera's-->
  <CameraAmount>1</CameraAmount>
  <!-- Error metric used: 1->normal collinearity metric, 2->disparity difference metric -->
  <ErrorMetric>2</ErrorMetric>
  <!-- Gradient based stopping condition-->
  <epsg>0.000001</epsg>
  <!-- Function-value based stopping condition-->
  <epsf>0</epsf>
  <!-- Step size-based stopping condition-->
  <epsx>0</epsx>
  <!-- Maximum number of iterations during optimization-->
  <maxits>0</maxits>
  <!-- Numerical differentation step for calculation of gradient-->
  <diffStep>0.01</diffStep>
  
</Settings>
</opencv_storage>
