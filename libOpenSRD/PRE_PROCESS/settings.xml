<?xml version="1.0"?>
<opencv_storage>
<Settings>

  <!-- Amount of threads used-->
  <ThreadAmount>1</ThreadAmount>

  <!-- Show image with found corners-->
  <showCorners>0</showCorners>
  <!-- Save errors in text file-->
  <saveErrors>1</saveErrors>
  <!-- Save feature coordinates in text file-->
  <saveFeatureCoordinates>1</saveFeatureCoordinates>
  <!-- Save camera pose estimation in text file-->
  <saveCameraPose>1</saveCameraPose>

  <!-- Type of reference input: image->true:1, file->false:0-->
  <InputTypeRef>1</InputTypeRef>
  <!-- Type of input: images->true:1, file->false:0-->
  <InputType>1</InputType>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 1-->
  <InputInitial1>"PRE_PROCESS/VerticesPoseEstimation_1.txt"</InputInitial1>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 2-->
  <InputInitial2>"PRE_PROCESS/VerticesPoseEstimation_2.txt"</InputInitial2>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 3-->
  <InputInitial3>"PRE_PROCESS/VerticesPoseEstimation_3.txt"</InputInitial3>
  <!-- Fixed location of points f for camera 1-->
  <InputFeatures1>"PRE_PROCESS/FeaturesF_1.txt"</InputFeatures1>
  <!-- Fixed location of points f for camera 2-->
  <InputFeatures2>"PRE_PROCESS/FeaturesF_2.txt"</InputFeatures2>
  <!-- Fixed location of points f for camera 3-->
  <InputFeatures3>"PRE_PROCESS/FeaturesF_3.txt"</InputFeatures3>
  <!-- Name of the input directory of camera 1-->
  <InputDirectory1>"DATA/CAM_1"</InputDirectory1>
  <!-- Name of the input directory of camera 2-->
  <InputDirectory2>"DATA/CAM_2"</InputDirectory2>
  <!-- Name of the input directory of camera 3-->
  <InputDirectory3>"DATA/CAM_3"</InputDirectory3>
  <!-- Name of the reference image/file - camera 1-->
  <InputReference1>"PRE_PROCESS/REF1.png"</InputReference1>
  <!-- Name of the reference image - camera 2-->
  <InputReference2>"PRE_PROCESS/REF2.png"</InputReference2>
  <!-- Name of the reference image - camera 3-->
  <InputReference3>"PRE_PROCESS/REF3.png"</InputReference3>
  
  <!-- Name of the calibration file of the camera 1-->
  <CalibrationFile1>"PRE_PROCESS/Calib_C1.yml"</CalibrationFile1>
  <!-- Name of the calibration file of the camera 2-->
  <CalibrationFile2>"PRE_PROCESS/Calib_C2.yml"</CalibrationFile2>
  <!-- Name of the calibration file of the camera 3-->
  <CalibrationFile3>"PRE_PROCESS/Calib_C3.yml"</CalibrationFile3>
  
  <!-- Name of ouput file for optimized coefficients according to chosen surface model-->
  <OutputFileName>"RESULTS/Coefficients.txt"</OutputFileName>
  <!-- Name of ouput file for average error per frame-->
  <OutputFileNameErrors>"RESULTS/Errors.txt"</OutputFileNameErrors>
  
  <!-- Name of ouput file for saving camera pose estimation camera 1-->
  <OutputCameraPose1>"RESULTS/Camera_Pose_1.txt"</OutputCameraPose1>
  <!-- Name of ouput file for saving camera pose estimation camera 2-->
  <OutputCameraPose2>"RESULTS/Camera_Pose_2.txt"</OutputCameraPose2>
  <!-- Name of ouput file for saving camera pose estimation camera 3-->
  <OutputCameraPose3>"RESULTS/Camera_Pose_3.txt"</OutputCameraPose3>
  
  <!-- Name of ouput directory for saving feature coordinates camera 1-->
  <OutputDirectory1>"RESULTS/FEATURES_1"</OutputDirectory1>
  <!-- Name of ouput directory for saving feature coordinates camera 2-->
  <OutputDirectory2>"RESULTS/FEATURES_2"</OutputDirectory2>
  <!-- Name of ouput directory for saving feature coordinates camera 3-->
  <OutputDirectory3>"RESULTS/FEATURES_3"</OutputDirectory3>
    
  <!-- Amount of parameters used-->
  <SurfaceModel>5</SurfaceModel>
  <!-- Size of a square for camera pose estimation in some user defined metric system (pixel, millimeter)-->
  <Square_Size>15</Square_Size>
  <!-- Length scale in x-direction (crosswise direction)(mm)-->
  <Lx>40</Lx>
  <!-- Length scale in y-direction (streamwise direction)(mm)-->
  <Ly>160</Ly>
  <!-- Initial guess to start optimization in each thread-->
  <Initialguess>"[70.0,0.000,0.000,0.000,0.000]"</Initialguess>
  <!-- Scaling of coefficients for optimization (length=SurfaceModel)-->
  <Scaling>"[1.0,10.000,10.000,10.000,10.000]"</Scaling>

  <!-- Number of rows and columns of reference pattern -->
  <BoardSize_Width>5</BoardSize_Width>
  <BoardSize_Height>17</BoardSize_Height>
  <!-- Number of rows and columns of feature pattern -->
  <PatternSize_Width>5</PatternSize_Width>
  <PatternSize_Height>17</PatternSize_Height>
  <!-- Threshold parameter for response strength corners-->
  <ResponseThreshold>350</ResponseThreshold>
  <!-- Minimum distance in pixels between corner points-->
  <MinDistance>15</MinDistance>
  <!-- Radius to calculate corner response: 5 or 10 currently possible -->
  <responseRadius>5</responseRadius>
  <!-- Maximum distance between located and predicted feature point -->
  <MatchesThreshold>10</MatchesThreshold>
  
  <!-- Amount of camera's-->
  <CameraAmount>1</CameraAmount>
  <!-- Error metric used: 1->normal collinearity metric, 2->disparity difference metric -->
  <ErrorMetric>2</ErrorMetric>
  <!-- Gradient based stopping condition-->
  <epsg>0.000001</epsg>
  <!-- Function-value based stopping condition-->
  <epsf>0</epsf>
  <!-- Step size-based stopping condition-->
  <epsx>0</epsx>
  <!-- Maximum number of iterations during optimization-->
  <maxits>0</maxits>
  <!-- Numerical differentation step for calculation of gradient-->
  <diffStep>0.01</diffStep>
  
</Settings>
</opencv_storage>
