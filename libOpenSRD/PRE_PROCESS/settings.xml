<?xml version="1.0"?>
<opencv_storage>
<Settings>
	
  <!-- Number of camera's-->
  <NumberOfCameras>1</NumberOfCameras>
  <!-- Type of reference input for camera pose estimation: image->true:1, file->false:0-->
  <TypeCameraPose>1</TypeCameraPose>
  <!-- Type of input for feature positions: images->true:1, file->false:0-->
  <TypeFeatureInput>1</TypeFeatureInput>
  <!-- Amount of threads used-->
  <ThreadAmount>1</ThreadAmount>
  
  <!-- Save camera pose estimation in text file-->
  <SaveCameraPose>1</SaveCameraPose>
  <!-- Save feature coordinates in text file-->
  <SaveFeatureCoordinates>1</SaveFeatureCoordinates>
  <!-- Show image with found corners-->
  <ShowCorners>0</ShowCorners>
  <!-- Save average residual error in text file-->
  <SaveResiduals>1</SaveResiduals>

  <!-- Name of the input directory of camera 1-->
  <InputDirectory1>"DATA/CAM_1"</InputDirectory1>
  <!-- Name of the input directory of camera 2-->
  <InputDirectory2>"DATA/CAM_2"</InputDirectory2>
  <!-- Name of the input directory of camera 3-->
  <InputDirectory3>"DATA/CAM_3"</InputDirectory3>
  <!-- Fixed location of points f for camera 1-->
  <InputFeatures1>"PRE_PROCESS/FeaturesF_1.txt"</InputFeatures1>
  <!-- Fixed location of points f for camera 2-->
  <InputFeatures2>"PRE_PROCESS/FeaturesF_2.txt"</InputFeatures2>
  <!-- Fixed location of points f for camera 3-->
  <InputFeatures3>"PRE_PROCESS/FeaturesF_3.txt"</InputFeatures3>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 1-->
  <InputInitial1>"PRE_PROCESS/VerticesPoseEstimation_1.txt"</InputInitial1>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 2-->
  <InputInitial2>"PRE_PROCESS/VerticesPoseEstimation_2.txt"</InputInitial2>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 3-->
  <InputInitial3>"PRE_PROCESS/VerticesPoseEstimation_3.txt"</InputInitial3>
  <!-- Name of the reference image/file - camera 1-->
  <InputReference1>"PRE_PROCESS/REF1.png"</InputReference1>
  <!-- Name of the reference image - camera 2-->
  <InputReference2>"PRE_PROCESS/REF2.png"</InputReference2>
  <!-- Name of the reference image - camera 3-->
  <InputReference3>"PRE_PROCESS/REF3.png"</InputReference3>
  
  <!-- Name of the calibration file of the camera 1-->
  <CalibrationFile1>"PRE_PROCESS/Calib_C1.yml"</CalibrationFile1>
  <!-- Name of the calibration file of the camera 2-->
  <CalibrationFile2>"PRE_PROCESS/Calib_C2.yml"</CalibrationFile2>
  <!-- Name of the calibration file of the camera 3-->
  <CalibrationFile3>"PRE_PROCESS/Calib_C3.yml"</CalibrationFile3>
  
  <!-- Name of ouput file for saving camera pose estimation camera 1-->
  <OutputCameraPose1>"RESULTS/Camera_Pose_1.txt"</OutputCameraPose1>
  <!-- Name of ouput file for saving camera pose estimation camera 2-->
  <OutputCameraPose2>"RESULTS/Camera_Pose_2.txt"</OutputCameraPose2>
  <!-- Name of ouput file for saving camera pose estimation camera 3-->
  <OutputCameraPose3>"RESULTS/Camera_Pose_3.txt"</OutputCameraPose3>
  <!-- Name of ouput directory for saving feature coordinates camera 1-->
  <OutputDirectory1>"RESULTS/FEATURES_1"</OutputDirectory1>
  <!-- Name of ouput directory for saving feature coordinates camera 2-->
  <OutputDirectory2>"RESULTS/FEATURES_2"</OutputDirectory2>
  <!-- Name of ouput directory for saving feature coordinates camera 3-->
  <OutputDirectory3>"RESULTS/FEATURES_3"</OutputDirectory3>
  <!-- Name of ouput file for optimized coefficients according to chosen surface model-->
  <OutputFileName>"RESULTS/Coefficients.txt"</OutputFileName>
  <!-- Name of ouput file for average residual error per frame-->
  <OutputFileNameResiudals>"RESULTS/Errors.txt"</OutputFileNameResiudals>
    
  
  <!-- Number of rows and columns of feature pattern -->
  <FeaturePatternSize_Width>5</FeaturePatternSize_Width>
  <FeaturePatternSize_Height>17</FeaturePatternSize_Height>
  <!-- Length scale in x-direction (crosswise direction)(mm)-->
  <Lx>40</Lx>
  <!-- Length scale in y-direction (streamwise direction)(mm)-->
  <Ly>160</Ly>
  <!-- Size of a square for camera pose estimation in some user defined metric system (pixel, millimeter)-->
  <Square_Size>15</Square_Size>
  <!-- Number of rows and columns of reference pattern -->
  <RefPatternSize_Width>5</RefPatternSize_Width>
  <RefPatternSize_Height>17</RefPatternSize_Height>


  <!-- Numerical differentation step for calculation of gradient-->
  <DiffStep>0.01</DiffStep>
  <!-- Function-value based stopping condition-->
  <Epsf>0</Epsf>
  <!-- Gradient based stopping condition-->
  <Epsg>0.000001</Epsg>
  <!-- Step size-based stopping condition-->
  <Epsx>0</Epsx>
  <!-- Error metric used: 1->normal collinearity metric, 2->disparity difference metric -->
  <ErrorMetric>2</ErrorMetric>
  <!-- Initial guess to start optimization in each thread-->
  <Initialguess>"[70.0,0.000,0.000,0.000,0.000]"</Initialguess>
  <!-- Maximum distance between located and predicted feature point -->
  <MatchesThreshold>10</MatchesThreshold>
  <!-- Maximum number of iterations during optimization-->
  <Maxits>0</Maxits>
  <!-- Minimum distance in pixels between corner points-->
  <MinDistance>15</MinDistance>
  <!-- Scaling of coefficients for optimization (length=SurfaceModelParameters)-->
  <Scaling>"[1.0,10.000,10.000,10.000,10.000]"</Scaling>
  <!-- Number of parameters used in the surface model-->
  <SurfaceModelParameters>5</SurfaceModelParameters>
  <!-- Radius to calculate corner response: 5 or 10 currently possible -->
  <ResponseRadius>5</ResponseRadius>
  <!-- Threshold parameter for response strength corners-->
  <ResponseThreshold>350</ResponseThreshold>

  
</Settings>
</opencv_storage>
