<?xml version="1.0"?>
<opencv_storage>
<Settings>
	
  <!-- Number of camera's-->
  <NumberOfCameras>1</NumberOfCameras>
  <!-- Type of reference input for camera pose estimation: image->true:1, file->false:0-->
  <TypeCameraPose>1</TypeCameraPose>
  <!-- Amount of threads used-->
  <ThreadAmount>1</ThreadAmount>
  
  <!-- Save camera pose estimation in text file-->
  <SaveCameraPose>1</SaveCameraPose>
  <!-- Show image with found corners-->
  <ShowCorners>0</ShowCorners>

  <!-- Name of the input directory of camera 1-->
  <InputDirectory1>"DATA/ProcessedPaper_CAM1"</InputDirectory1>
  <!-- Name of the input directory of camera 2-->
  <InputDirectory2>"DATA/ProcessedPaper_CAM2"</InputDirectory2>
  <!-- Name of the input directory of camera 3-->
  <InputDirectory3>"DATA/ProcessedPaper_CAM3"</InputDirectory3>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 1-->
  <InputInitial1>"INPUT/VerticesPoseEstimation_CAM1.txt"</InputInitial1>
   <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 2-->
  <InputInitial2>"INPUT/VerticesPoseEstimation_CAM2.txt"</InputInitial2>
  <!-- Location of checkerboard vertices w.r.t. to world coordinate system during camera pose estimation of camera 3-->
  <InputInitial3>"INPUT/VerticesPoseEstimation_CAM3.txt"</InputInitial3>
  <!-- Name of the reference image/file - camera 1-->
  <InputReference1>"INPUT/ReferencePattern_CAM1.png"</InputReference1>
  <!-- Name of the reference image - camera 2-->
  <InputReference2>"INPUT/ReferencePattern_CAM2.png"</InputReference2>
  <!-- Name of the reference image - camera 3-->
  <InputReference3>"INPUT/ReferencePattern_CAM3.png"</InputReference3>
  
  <!-- Name of the calibration file of camera 1-->
  <CalibrationFile1>"INPUT/Calib_CAM1.yml"</CalibrationFile1>
  <!-- Name of the calibration file of camera 2-->
  <CalibrationFile2>"INPUT/Calib_CAM2.yml"</CalibrationFile2>
  <!-- Name of the calibration file of camera 3-->
  <CalibrationFile3>"INPUT/Calib_CAM3.yml"</CalibrationFile3>
  
  <!-- Name of output file for saving camera pose estimation camera 1-->
  <OutputCameraPose1>"RESULTS/Camera_Pose_1.txt"</OutputCameraPose1>
  <!-- Name of output file for saving camera pose estimation camera 2-->
  <OutputCameraPose2>"RESULTS/Camera_Pose_1.txt"</OutputCameraPose2>
  <!-- Name of output file for saving camera pose estimation camera 3-->
  <OutputCameraPose3>"RESULTS/Camera_Pose_1.txt"</OutputCameraPose3>
  <!-- Name of output file for optimized coefficients according to chosen surface model-->
  <OutputFileName>"RESULTS/TimeSeries_CAM1.txt"</OutputFileName>
   <!-- Name of output file for center location processed area per frame-->
  <OutputFileCenters>"RESULTS/CentersReconstructedArea.txt"</OutputFileCenters>
 
  
  <!-- Length scale in x-direction (lateral direction)(mm)-->
  <Lx>100</Lx>
  <!-- Length scale in y-direction (streamwise direction)(mm)-->
  <Ly>100</Ly>
  <!-- Number of rows and columns of reference pattern -->
  <RefPatternSize_Width>10</RefPatternSize_Width>
  <RefPatternSize_Height>39</RefPatternSize_Height>
  <!-- Width/length of checquerboard squares-->
  <gridSize>10</gridSize>
  

 <!-- Minimum distance in pixels between corner points-->
  <MinDistance>18</MinDistance>
  <!-- Radius to calculate corner response: 5 or 10 currently possible -->
  <ResponseRadius>5</ResponseRadius>
  <!-- Threshold parameter for response strength corners-->
  <ResponseThreshold>400</ResponseThreshold>

     <!-- Minimum u-coordinate of reconstructed image area-->
  <min_u>1300</min_u>
   <!-- Maximum u-coordinate of reconstructed image area-->
  <max_u>1550</max_u>
   <!-- Minimum u-coordinate of reconstructed image area-->
  <min_v>100</min_v>
   <!-- Maximum u-coordinate of reconstructed image area-->
  <max_v>300</max_v>
  
   <!-- Threshold parameter for detecting black parts in image-->
  <minThreshold>90</minThreshold>
   <!-- Threshold parameter for detecting white parts in image-->
  <maxThreshold>95</maxThreshold>
  <!-- Numerical differentation step for calculation of gradient-->
  <DiffStep>5</DiffStep>
  <!-- Function-value based stopping condition-->
  <Epsf>0</Epsf>
  <!-- Gradient based stopping condition-->
  <Epsg>0.000000001</Epsg>
  <!-- Step size-based stopping condition-->
  <Epsx>0</Epsx>
    <!-- Maximum number of iterations during optimization-->
  <MaxIts>0</MaxIts>
  <!-- Initial guess to start optimization in each thread-->
  <InitialGuess>"[77.00,-3.5000]"</InitialGuess>
  <!-- Number of parameters used in the surface model-->
  <SurfaceModelParameters>3</SurfaceModelParameters>
  <!-- Scaling of coefficients for optimization (length=SurfaceModelParameters)-->
  <Scaling>"[1.0,1.0]"</Scaling>
  
  
  

</Settings>
</opencv_storage>
